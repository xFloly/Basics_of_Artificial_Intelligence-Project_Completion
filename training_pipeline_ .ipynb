{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from hyperopt import fmin, rand, tpe, space_eval, STATUS_OK, Trials, hp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data_sets/train.csv')\n",
    "df_test = pd.read_csv('./data_sets/test.csv')\n",
    "df_train.drop_duplicates(inplace=True)\n",
    "df_train.drop(columns=['Descript', 'Resolution', 'Address','DayOfWeek'], inplace=True)\n",
    "df_test.drop(columns=['Address','DayOfWeek'], inplace=True)\n",
    "id_test = df_test.pop('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.replace({'X': -120.5, 'Y': 90.0}, np.NaN, inplace=True)\n",
    "df_test.replace({'X': -120.5, 'Y': 90.0}, np.NaN, inplace=True)\n",
    "\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "\n",
    "for district in df_train['PdDistrict'].unique():\n",
    "    df_train.loc[df_train['PdDistrict'] == district, ['X', 'Y']] = imp.fit_transform(\n",
    "        df_train.loc[df_train['PdDistrict'] == district, ['X', 'Y']])\n",
    "    df_test.loc[df_test['PdDistrict'] == district, ['X', 'Y']] = imp.transform(\n",
    "        df_test.loc[df_test['PdDistrict'] == district, ['X', 'Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['Category']\n",
    "df_train = df_train.drop('Category', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df  = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[self.column] = pd.to_datetime(X[self.column])\n",
    "        X['day'] = X[self.column].dt.day - 1\n",
    "        X['month'] = X[self.column].dt.month - 1\n",
    "        X['year'] = X[self.column].dt.year\n",
    "        X['hour'] = X[self.column].dt.hour\n",
    "        X['quarter'] = X[self.column].dt.quarter - 1\n",
    "        X['dayofyear'] = X[self.column].dt.dayofyear - 1\n",
    "        X['dayofweek'] = X[self.column].dt.dayofweek\n",
    "        X['is_weekend'] = (\n",
    "            X[self.column].dt.dayofweek >= 5).astype(int)\n",
    "        X['minute'] = X[self.column].dt.minute\n",
    "        X=X.drop(columns=self.column)\n",
    "        return X\n",
    "\n",
    "\n",
    "class CosTransformation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column, minus=False):\n",
    "        self.period = None\n",
    "        self.minus = minus\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.minus = -1 if self.minus else 1\n",
    "        self.period = X[self.column].nunique()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[self.column + 'cos'] = self.minus * \\\n",
    "            np.cos(X[self.column] * 2 * np.pi / self.period)\n",
    "        return X\n",
    "\n",
    "\n",
    "class SinTransformation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column, minus=False):\n",
    "        self.period = None\n",
    "        self.minus = minus\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.minus = -1 if self.minus else 1\n",
    "        self.period = X[self.column].nunique()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[self.column + 'sin'] = self.minus * \\\n",
    "            np.sin(X[self.column] * 2 * np.pi / self.period)\n",
    "        return X\n",
    "\n",
    "\n",
    "class BucketingCoordinatesTransformation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=['X', 'Y'], bins=10):\n",
    "        self.columns = columns\n",
    "        self.bins = bins\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.x_mean = X[self.columns[0]].mean()\n",
    "        self.y_mean = X[self.columns[1]].mean()\n",
    "        self.x_std = X[self.columns[0]].std()\n",
    "        self.y_std = X[self.columns[1]].std()\n",
    "\n",
    "        self.x_min = ((X[self.columns[0]] - self.x_mean) / self.x_std).min()\n",
    "        self.x_max = ((X[self.columns[0]] - self.x_mean) / self.x_std).max()\n",
    "        self.y_min = ((X[self.columns[1]] - self.y_mean) / self.y_std).min()\n",
    "        self.y_max = ((X[self.columns[1]] - self.y_mean) / self.y_std).max()\n",
    "\n",
    "        self.bin_edges_x = np.linspace(self.x_min, self.x_max, self.bins)\n",
    "        self.bin_edges_y = np.linspace(self.y_min, self.y_max, self.bins)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X['sector_x'] = pd.cut((X[self.columns[0]] - self.x_mean) / self.x_std,\n",
    "                               bins=self.bin_edges_x, labels=False, include_lowest=True)\n",
    "        X['sector_y'] = pd.cut((X[self.columns[1]] - self.y_mean) / self.y_std,\n",
    "                               bins=self.bin_edges_y, labels=False, include_lowest=True)\n",
    "        X = X.drop(columns=self.columns)\n",
    "        return X\n",
    "\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.drop(['day', 'month', 'year', 'hour', 'quarter',\n",
    "               'dayofweek', 'minute', 'dayofyear'], axis=1)\n",
    "    return X\n",
    "\n",
    "\n",
    "drop_columns_transformer = FunctionTransformer(drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_transformer = Pipeline([\n",
    "    ('cos_transformation_hour', CosTransformation(column='hour')),\n",
    "    ('cos_transformation_month', CosTransformation(column='month')),\n",
    "    ('cos_transformation_quarter', CosTransformation(column='quarter')),\n",
    "    ('cos_transformation_dayofyear', CosTransformation(column='dayofyear')),\n",
    "    ('cos_transformation_day', CosTransformation(column='day')),\n",
    "    ('cos_transformation_dayofweek', CosTransformation(column='dayofweek'))\n",
    "])\n",
    "sin_transformer = Pipeline([\n",
    "    ('sin_transformation_hour', SinTransformation(column='hour')),\n",
    "    ('sin_transformation_month', SinTransformation(column='month')),\n",
    "    ('sin_transformation_quarter', SinTransformation(column='quarter')),\n",
    "    ('sin_transformation_dayofyear', SinTransformation(column='dayofyear')),\n",
    "    ('sin_transformation_day', SinTransformation(column='day')),\n",
    "    ('sin_transformation_dayofweek', SinTransformation(column='dayofweek'))\n",
    "\n",
    "])\n",
    "\n",
    "base_transformer = Pipeline([\n",
    "    ('date_features', DateFeatureExtractor(column='Dates')),\n",
    "])\n",
    "sincos_transformer = Pipeline([\n",
    "    ('date_features', DateFeatureExtractor(column='Dates')),\n",
    "    ('cos', cos_transformer),\n",
    "    ('sin', sin_transformer),\n",
    "    ('drop', drop_columns_transformer)\n",
    "\n",
    "])\n",
    "\n",
    "bucketing_transformer = Pipeline([\n",
    "    ('date_features', DateFeatureExtractor(column='Dates')),\n",
    "    ('cos', cos_transformer),\n",
    "    ('sin', sin_transformer),\n",
    "    ('drop', drop_columns_transformer),\n",
    "    ('bucketing', BucketingCoordinatesTransformation(\n",
    "        columns=['X', 'Y'], bins=10))\n",
    "])\n",
    "\n",
    "categorical_transformer_label = Pipeline(steps=[\n",
    "    ('label', OrdinalEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder=LabelEncoder()\n",
    "y=label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_base = base_transformer.fit_transform(base_df)\n",
    "df_test_base = base_transformer.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat_label', categorical_transformer_label, ['PdDistrict']),\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(df_train_base)\n",
    "X_test = preprocessor.transform(df_test_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trenowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm                     | Parameters                  | Logloss            |\n",
    "|-------------------------------|-----------------------------|--------------------|\n",
    "| Stochastic Gradient Descent   | Default Parameters          | 20.10143           |\n",
    "| K-Nearest Neighbors           | Default Parameters          | 26.25314           |\n",
    "| HistGradientBoostingClassifier| Default Parameters          | 6.59939            |\n",
    "| XGBoost                       | Default Parameters          | 2.29494            |\n",
    "| LightGBM                      | Default Parameters          | 2.59236            |\n",
    "| Random Forest                 | Default Parameters          | 5.03352            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatecznie, spośród algorytmów, które osiągnęły wynik poniżej 3.0, zdecydowaliśmy się pracować z XGBoost i LightGBM ze względu na ich efektywność i wszechstronność w dostrajaniu hiperparametrów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soszy\\anaconda3\\envs\\effi-python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss: 20.10143316473642\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sgd = SGDClassifier(loss='log_loss')\n",
    "\n",
    "y_prob = cross_val_predict(sgd, X_train, y, method='predict_proba', n_jobs=-1)\n",
    "\n",
    "\n",
    "logloss = log_loss(y, y_prob)\n",
    "\n",
    "print(f'LogLoss: {logloss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogLoss: 20.10143316473642"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soszy\\anaconda3\\envs\\effi-python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss: 26.253138564296812\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "y_prob = cross_val_predict(knn, X_train, y, method='predict_proba',n_jobs=-1)\n",
    "\n",
    "logloss = log_loss(y, y_prob)\n",
    "print(f'LogLoss: {logloss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogLoss: 26.253138564296812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soszy\\anaconda3\\envs\\effi-python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss: 6.599390039999148\n"
     ]
    }
   ],
   "source": [
    "hgb = HistGradientBoostingClassifier()\n",
    "\n",
    "y_prob = cross_val_predict(hgb, X_train, y, method='predict_proba', n_jobs=-1)\n",
    "\n",
    "logloss = log_loss(y, y_prob)\n",
    "\n",
    "print(f'LogLoss: {logloss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogLoss: 6.599390039999148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  2.294936056193336\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'device':'cuda',\n",
    "    'tree_method': 'hist',\n",
    "    'num_class': 39,\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'objective': 'multi:softprob'\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y)\n",
    "\n",
    "cv_results = xgb.cv(\n",
    "    params=xgb_params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=100,\n",
    "    nfold=5,\n",
    "    metrics='mlogloss',\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "print('Best score: ', cv_results['test-mlogloss-mean'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = np.argmin(cv_results['test-mlogloss-mean'].min())\n",
    "print('Best epoch: ', num_boost_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(xgb_params, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_test)\n",
    "predictions = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(predictions,\n",
    "                          columns=label_encoder.classes_,\n",
    "                          index=id_test)\n",
    "submission.to_csv('models/XGBM - base model.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score:  2.294936056193336 XGB VALIDATION CV TEST RESULTS: 2.30348 ON KAGGLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=lgbm.Dataset(X_train, label=y,categorical_feature=[0],free_raw_data=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgbm = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 39\n",
    "}\n",
    "cv_results = lgbm.cv(params_lgbm, train,\n",
    "                    metrics='multi_logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  2.592361487579474\n"
     ]
    }
   ],
   "source": [
    "print('Best score: ', min(cv_results['valid multi_logloss-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 918\n",
      "[LightGBM] [Info] Number of data points in the train set: 875726, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -6.361620\n",
      "[LightGBM] [Info] Start training from score -2.433653\n",
      "[LightGBM] [Info] Start training from score -7.676455\n",
      "[LightGBM] [Info] Start training from score -8.016382\n",
      "[LightGBM] [Info] Start training from score -3.175005\n",
      "[LightGBM] [Info] Start training from score -5.313420\n",
      "[LightGBM] [Info] Start training from score -5.956155\n",
      "[LightGBM] [Info] Start training from score -2.787570\n",
      "[LightGBM] [Info] Start training from score -5.321801\n",
      "[LightGBM] [Info] Start training from score -6.623191\n",
      "[LightGBM] [Info] Start training from score -8.137631\n",
      "[LightGBM] [Info] Start training from score -7.492493\n",
      "[LightGBM] [Info] Start training from score -4.414954\n",
      "[LightGBM] [Info] Start training from score -3.963424\n",
      "[LightGBM] [Info] Start training from score -8.699202\n",
      "[LightGBM] [Info] Start training from score -5.924902\n",
      "[LightGBM] [Info] Start training from score -1.614161\n",
      "[LightGBM] [Info] Start training from score -6.133726\n",
      "[LightGBM] [Info] Start training from score -6.586915\n",
      "[LightGBM] [Info] Start training from score -3.529769\n",
      "[LightGBM] [Info] Start training from score -2.254189\n",
      "[LightGBM] [Info] Start training from score -1.939089\n",
      "[LightGBM] [Info] Start training from score -10.591766\n",
      "[LightGBM] [Info] Start training from score -4.767376\n",
      "[LightGBM] [Info] Start training from score -5.633381\n",
      "[LightGBM] [Info] Start training from score -3.640081\n",
      "[LightGBM] [Info] Start training from score -6.136362\n",
      "[LightGBM] [Info] Start training from score -4.474570\n",
      "[LightGBM] [Info] Start training from score -5.298005\n",
      "[LightGBM] [Info] Start training from score -8.685596\n",
      "[LightGBM] [Info] Start training from score -5.262787\n",
      "[LightGBM] [Info] Start training from score -7.452327\n",
      "[LightGBM] [Info] Start training from score -3.328436\n",
      "[LightGBM] [Info] Start training from score -11.891049\n",
      "[LightGBM] [Info] Start training from score -4.784716\n",
      "[LightGBM] [Info] Start training from score -2.977745\n",
      "[LightGBM] [Info] Start training from score -2.791529\n",
      "[LightGBM] [Info] Start training from score -3.033937\n",
      "[LightGBM] [Info] Start training from score -4.629122\n"
     ]
    }
   ],
   "source": [
    "bst = lgbm.train(params_lgbm, train, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(predictions,\n",
    "                          columns=label_encoder.classes_,\n",
    "                          index=id_test)\n",
    "submission.to_csv('models/LGBM - base model.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "y_prob = cross_val_predict(clf, X_train, y, method='predict_proba', n_jobs=-1)\n",
    "\n",
    "logloss = log_loss(y, y_prob)\n",
    "print(f'LogLoss: {logloss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score:  5.033523749445065 RANDOM FOREST VALIDATION CV\n",
    "TEST RESULTS:  3.81670 ON KAGGLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunowanie Hiperparametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Próbowaliśmy dostrajać hiperparametry przy użyciu Random Grid Search, ale postanowiliśmy skorzystać z optymalizacji bayesowskiej. \n",
    "\n",
    "### Optymalizacja Bayesowska\n",
    "\n",
    "Optymalizacja bayesowska to metoda optymalizacji hiperparametrów, która buduje probabilistyczny model funkcji celu i wykorzystuje go do wyboru najbardziej obiecujących hiperparametrów do przetestowania. W przeciwieństwie do Random Grid Search, który losowo próbuje różne kombinacje hiperparametrów, optymalizacja bayesowska inteligentnie nawigując przestrzenią hiperparametrów, aby szybciej znaleźć optymalne ustawienia.\n",
    "\n",
    "Dzięki zastosowaniu optymalizacji bayesowskiej możemy bardziej efektywnie dostrajać nasze modele XGBoost i LightGBM, co prowadzi do lepszych wyników predykcyjnych przy mniejszej liczbie prób.\n",
    "\n",
    "### Pipeline'y do Przetwarzania Danych\n",
    "\n",
    "W celu skutecznego przetwarzania danych i porównania różnych podejść, zastosowaliśmy trzy różne pipeline'y:\n",
    "\n",
    "1. **Pipeline z rozdzielonymi datami**:\n",
    "   - W tym pipeline'ie rozdzieliliśmy daty na oddzielne kolumny reprezentujące dni, miesiące i godziny. Pozwoliło to modelowi na lepsze zrozumienie czasowych wzorców w danych.\n",
    "\n",
    "2. **Pipeline z funkcjami trygonometrycznymi**:\n",
    "   - W tym podejściu zastosowaliśmy funkcje trygonometryczne (sinus i cosinus) do przekształcenia dni, miesięcy i godzin. Dzięki temu mogliśmy uchwycić cykliczność w danych, co mogło poprawić wydajność modeli.\n",
    "\n",
    "3. **Pipeline z funkcjami trygonometrycznymi i bucketowaniem**:\n",
    "   - Ten pipeline łączył funkcje trygonometryczne z techniką grupowania (bucketing) współrzędnych geograficznych. Podzieliliśmy szerokość i długość geograficzną na mniejsze segmenty (wiaderka), aby uwzględnić podobieństwa między miejscami znajdującymi się blisko siebie.\n",
    "\n",
    "Każdy z tych pipeline'ów został zaprojektowany w celu poprawy wyników predykcyjnych naszych modeli poprzez różne techniki przetwarzania danych.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "| Model           | Metoda                             | Wynik CV                | Wynik Kaggle          |\n",
    "|-----------------|--------------------------------------|-------------------------|-----------------------|\n",
    "| XGBoost         | Bez hiperparametrów                  | 2.29494                 | 2.30348               |\n",
    "| XGBoost         | Pipeline 1                           | 2.28839                 | 2.30605               |\n",
    "| XGBoost         | Pipeline 2                           | 2.27688                 | 2.29785               |\n",
    "| XGBoost         | Pipeline 3                           | 2.50038                 | 2.52143               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "\n",
    "    # Convert hyperparameters to correct types\n",
    "    params = {\n",
    "        'learning_rate': float(params['learning_rate']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'subsample': float(params['subsample']),\n",
    "        'colsample_bytree': float(params['colsample_bytree']),\n",
    "        'reg_lambda': float(params['reg_lambda']),\n",
    "        'gamma': float(params['gamma']),\n",
    "        'min_child_weight': int(params['min_child_weight']),\n",
    "\n",
    "        # Fixed parameters\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 39,\n",
    "        'verbosity': 0,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'device':'cuda',\n",
    "        'tree_method': 'hist'\n",
    "    }\n",
    "\n",
    "    # Train using cross-validation\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=100,\n",
    "        nfold=5,\n",
    "        stratified=True,\n",
    "        metrics='mlogloss',\n",
    "        early_stopping_rounds=10,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    loss = min(cv_results['test-mlogloss-mean'])\n",
    "    epochs = np.argmin(cv_results['test-mlogloss-mean']) + 1\n",
    "\n",
    "    print('loss:', loss)\n",
    "\n",
    "    return {\n",
    "        'loss': loss,\n",
    "        'params': params,\n",
    "        'status': STATUS_OK,\n",
    "        'epochs': epochs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1)),\n",
    "    'max_depth': hp.quniform('max_depth', 1, 20, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 5.0),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = base_df\n",
    "dtrain = xgb.DMatrix(X_train, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:                                                 \n",
      "2.334618900317089                                     \n",
      "loss:                                                                           \n",
      "2.75388501919925                                                                \n",
      "loss:                                                                           \n",
      "2.5812220854607957                                                              \n",
      "loss:                                                                           \n",
      "2.2883935014434504                                                              \n",
      "loss:                                                                            \n",
      "2.531286980250815                                                                \n",
      "loss:                                                                            \n",
      "2.9472151314701294                                                               \n",
      "loss:                                                                            \n",
      "2.7554300087574752                                                               \n",
      "loss:                                                                            \n",
      "2.5779933236503574                                                               \n",
      "loss:                                                                            \n",
      "2.3103558712382855                                                               \n",
      "loss:                                                                            \n",
      "2.405543696505282                                                                \n",
      "100%|██████████| 10/10 [56:28<00:00, 338.89s/trial, best loss: 2.2883935014434504]\n"
     ]
    }
   ],
   "source": [
    "tpe_algo = tpe.suggest\n",
    "tpe_trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe_algo,\n",
    "    max_evals=10,\n",
    "    trials=tpe_trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6327741097399604,\n",
       " 'gamma': 2.1259392559055446,\n",
       " 'learning_rate': 0.09797353834548439,\n",
       " 'max_depth': 20.0,\n",
       " 'min_child_weight': 2.0,\n",
       " 'reg_lambda': 0.7764276919090378,\n",
       " 'subsample': 0.3738444042140795}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 0.6327741097399604,\n",
    " 'gamma': 2.1259392559055446,\n",
    " 'learning_rate': 0.09797353834548439,\n",
    " 'max_depth': 20,\n",
    " 'min_child_weight': 2.0,\n",
    " 'reg_lambda': 0.7764276919090378,\n",
    " 'subsample': 0.3738444042140795,\n",
    "         # Fixed parameters\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 39,\n",
    "        'verbosity': 0,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'device':'cuda',\n",
    "        'tree_method': 'hist'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bst.predict(dtest)\n",
    "submission = pd.DataFrame(predictions,\n",
    "                          columns=label_encoder.classes_,\n",
    "                          index=id_test)\n",
    "submission.to_csv('models/XGBM - model tuned.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val accuracy 2.2883935014434504  kaggle 2.30605"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SinCos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_xgb3 = sincos_transformer.fit_transform(df_train)\n",
    "df_test_xgb3 = sincos_transformer.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat_label', categorical_transformer_label, ['PdDistrict']),\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(df_train_xgb3)\n",
    "X_test = preprocessor.transform(df_test_xgb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>quarter</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>...</th>\n",
       "      <th>quartercos</th>\n",
       "      <th>dayofyearcos</th>\n",
       "      <th>daycos</th>\n",
       "      <th>dayofweekcos</th>\n",
       "      <th>hoursin</th>\n",
       "      <th>monthsin</th>\n",
       "      <th>quartersin</th>\n",
       "      <th>dayofyearsin</th>\n",
       "      <th>daysin</th>\n",
       "      <th>dayofweeksin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-0.772642</td>\n",
       "      <td>-0.758758</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634842</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>0.974928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-0.772642</td>\n",
       "      <td>-0.758758</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634842</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>0.974928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-0.772642</td>\n",
       "      <td>-0.758758</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634842</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>0.974928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-0.772642</td>\n",
       "      <td>-0.758758</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634842</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>0.974928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PARK</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-0.772642</td>\n",
       "      <td>-0.758758</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634842</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>0.974928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878044</th>\n",
       "      <td>TARAVAL</td>\n",
       "      <td>-122.459033</td>\n",
       "      <td>37.714056</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.995684</td>\n",
       "      <td>0.528964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092813</td>\n",
       "      <td>0.848644</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878045</th>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>-122.447364</td>\n",
       "      <td>37.731948</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.995684</td>\n",
       "      <td>0.528964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092813</td>\n",
       "      <td>0.848644</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878046</th>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>-122.403390</td>\n",
       "      <td>37.780266</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.995684</td>\n",
       "      <td>0.528964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092813</td>\n",
       "      <td>0.848644</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878047</th>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>-122.390531</td>\n",
       "      <td>37.780607</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.995684</td>\n",
       "      <td>0.528964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092813</td>\n",
       "      <td>0.848644</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878048</th>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>-122.394926</td>\n",
       "      <td>37.738212</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.995684</td>\n",
       "      <td>0.528964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092813</td>\n",
       "      <td>0.848644</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>875726 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PdDistrict           X          Y  day  month  year  hour  quarter  \\\n",
       "0        NORTHERN -122.425892  37.774599   12      4  2015    23        1   \n",
       "1        NORTHERN -122.425892  37.774599   12      4  2015    23        1   \n",
       "2        NORTHERN -122.424363  37.800414   12      4  2015    23        1   \n",
       "3        NORTHERN -122.426995  37.800873   12      4  2015    23        1   \n",
       "4            PARK -122.438738  37.771541   12      4  2015    23        1   \n",
       "...           ...         ...        ...  ...    ...   ...   ...      ...   \n",
       "878044    TARAVAL -122.459033  37.714056    5      0  2003     0        0   \n",
       "878045  INGLESIDE -122.447364  37.731948    5      0  2003     0        0   \n",
       "878046   SOUTHERN -122.403390  37.780266    5      0  2003     0        0   \n",
       "878047   SOUTHERN -122.390531  37.780607    5      0  2003     0        0   \n",
       "878048    BAYVIEW -122.394926  37.738212    5      0  2003     0        0   \n",
       "\n",
       "        dayofyear  dayofweek  ...    quartercos  dayofyearcos    daycos  \\\n",
       "0             132          2  ...  6.123234e-17     -0.772642 -0.758758   \n",
       "1             132          2  ...  6.123234e-17     -0.772642 -0.758758   \n",
       "2             132          2  ...  6.123234e-17     -0.772642 -0.758758   \n",
       "3             132          2  ...  6.123234e-17     -0.772642 -0.758758   \n",
       "4             132          2  ...  6.123234e-17     -0.772642 -0.758758   \n",
       "...           ...        ...  ...           ...           ...       ...   \n",
       "878044          5          0  ...  1.000000e+00      0.995684  0.528964   \n",
       "878045          5          0  ...  1.000000e+00      0.995684  0.528964   \n",
       "878046          5          0  ...  1.000000e+00      0.995684  0.528964   \n",
       "878047          5          0  ...  1.000000e+00      0.995684  0.528964   \n",
       "878048          5          0  ...  1.000000e+00      0.995684  0.528964   \n",
       "\n",
       "        dayofweekcos   hoursin  monthsin  quartersin  dayofyearsin    daysin  \\\n",
       "0          -0.222521 -0.258819  0.866025         1.0      0.634842  0.651372   \n",
       "1          -0.222521 -0.258819  0.866025         1.0      0.634842  0.651372   \n",
       "2          -0.222521 -0.258819  0.866025         1.0      0.634842  0.651372   \n",
       "3          -0.222521 -0.258819  0.866025         1.0      0.634842  0.651372   \n",
       "4          -0.222521 -0.258819  0.866025         1.0      0.634842  0.651372   \n",
       "...              ...       ...       ...         ...           ...       ...   \n",
       "878044      1.000000  0.000000  0.000000         0.0      0.092813  0.848644   \n",
       "878045      1.000000  0.000000  0.000000         0.0      0.092813  0.848644   \n",
       "878046      1.000000  0.000000  0.000000         0.0      0.092813  0.848644   \n",
       "878047      1.000000  0.000000  0.000000         0.0      0.092813  0.848644   \n",
       "878048      1.000000  0.000000  0.000000         0.0      0.092813  0.848644   \n",
       "\n",
       "        dayofweeksin  \n",
       "0           0.974928  \n",
       "1           0.974928  \n",
       "2           0.974928  \n",
       "3           0.974928  \n",
       "4           0.974928  \n",
       "...              ...  \n",
       "878044      0.000000  \n",
       "878045      0.000000  \n",
       "878046      0.000000  \n",
       "878047      0.000000  \n",
       "878048      0.000000  \n",
       "\n",
       "[875726 rows x 24 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_xgb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:                                                 \n",
      "2.854777294781713                                     \n",
      "loss:                                                                           \n",
      "2.421471975816339                                                               \n",
      "loss:                                                                           \n",
      "2.3408720883361314                                                              \n",
      "loss:                                                                            \n",
      "2.276883080686809                                                                \n",
      "loss:                                                                            \n",
      "2.3542853164856172                                                              \n",
      "loss:                                                                           \n",
      "2.3324126709732504                                                              \n",
      "loss:                                                                           \n",
      "2.451604397497873                                                               \n",
      "loss:                                                                           \n",
      "2.4092263168485974                                                              \n",
      "loss:                                                                           \n",
      "2.656962286070278                                                               \n",
      "loss:                                                                           \n",
      "2.60233681115065                                                                \n",
      "100%|██████████| 10/10 [58:36<00:00, 351.65s/trial, best loss: 2.276883080686809]\n"
     ]
    }
   ],
   "source": [
    "tpe_algo = tpe.suggest\n",
    "tpe_trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe_algo,\n",
    "    max_evals=10,\n",
    "    trials=tpe_trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8399515080498189,\n",
       " 'gamma': 1.8809687874683567,\n",
       " 'learning_rate': 0.15019457619783694,\n",
       " 'max_depth': 12.0,\n",
       " 'min_child_weight': 9.0,\n",
       " 'reg_lambda': 0.3917588749286913,\n",
       " 'subsample': 0.8665760243726364}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'colsample_bytree': 0.8399515080498189,\n",
    " 'gamma': 1.8809687874683567,\n",
    " 'learning_rate': 0.15019457619783694,\n",
    " 'max_depth': 12.0,\n",
    " 'min_child_weight': 9.0,\n",
    " 'reg_lambda': 0.3917588749286913,\n",
    " 'subsample': 0.8665760243726364}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 0.8399515080498189,\n",
    " 'gamma': 1.8809687874683567,\n",
    " 'learning_rate': 0.15019457619783694,\n",
    " 'max_depth': 12,\n",
    " 'min_child_weight': 9.0,\n",
    " 'reg_lambda': 0.3917588749286913,\n",
    " 'subsample': 0.8665760243726364,\n",
    "  'objective': 'multi:softprob',\n",
    "  'num_class': 39,\n",
    "  'verbosity': 0,\n",
    "  'eval_metric': 'mlogloss',\n",
    "  'device':'cuda',\n",
    "  'tree_method': 'hist'\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bst.predict(dtest)\n",
    "submission = pd.DataFrame(predictions,\n",
    "                          columns=label_encoder.classes_,\n",
    "                          index=id_test)\n",
    "submission.to_csv('models/XGBM - sincos model tuned.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val loss: 2.276883080686809  keggle: 2.27688   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_xgb2 = bucketing_transformer.fit_transform(df_train)\n",
    "df_test_xgb2 = bucketing_transformer.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soszy\\AppData\\Local\\Temp\\ipykernel_14308\\517034797.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test_xgb2.sector_x.fillna(8, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_test_xgb2.sector_x.fillna(8, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soszy\\AppData\\Local\\Temp\\ipykernel_14308\\4044077216.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test_xgb2.sector_y.fillna(8, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_test_xgb2.sector_y.fillna(8, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_xgb2 = df_train_xgb2.drop(['day', 'month', 'hour','quarter','dayofyear','dayofweek','minute','X','Y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_xgb2 = df_test_xgb2.drop(['day', 'month', 'hour', 'quarter', 'dayofyear','dayofweek','minute','X','Y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat_label', categorical_transformer_label, ['PdDistrict']),\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(df_train_xgb2)\n",
    "X_test = preprocessor.transform(df_test_xgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:                                                 \n",
      "2.50343654568066                                      \n",
      "loss:                                                                          \n",
      "2.5571448296583887                                                             \n",
      "loss:                                                                          \n",
      "2.5003795260570145                                                             \n",
      "loss:                                                                            \n",
      "2.8357352817765586                                                               \n",
      "loss:                                                                            \n",
      "2.538878462258584                                                                \n",
      "loss:                                                                            \n",
      "2.8956564616631333                                                               \n",
      "loss:                                                                            \n",
      "2.558739765049625                                                                \n",
      "loss:                                                                            \n",
      "2.6120653202165056                                                               \n",
      "loss:                                                                            \n",
      "2.6685666227966616                                                               \n",
      "loss:                                                                            \n",
      "2.51368352585862                                                                   \n",
      "100%|██████████| 10/10 [1:01:10<00:00, 367.09s/trial, best loss: 2.5003795260570145]\n"
     ]
    }
   ],
   "source": [
    "tpe_algo = tpe.suggest\n",
    "tpe_trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe_algo,\n",
    "    max_evals=10,\n",
    "    trials=tpe_trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7771885113792781,\n",
       " 'gamma': 4.26023572510469,\n",
       " 'learning_rate': 0.08290773728323132,\n",
       " 'max_depth': 11.0,\n",
       " 'min_child_weight': 5.0,\n",
       " 'reg_lambda': 0.38119084682817406,\n",
       " 'subsample': 0.7629235886854302}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'colsample_bytree': 0.7771885113792781,\n",
    " 'gamma': 4.26023572510469,\n",
    " 'learning_rate': 0.08290773728323132,\n",
    " 'max_depth': 11.0,\n",
    " 'min_child_weight': 5.0,\n",
    " 'reg_lambda': 0.38119084682817406,\n",
    " 'subsample': 0.7629235886854302}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 0.6327741097399604,\n",
    " 'gamma': 2.1259392559055446,\n",
    " 'learning_rate': 0.09797353834548439,\n",
    " 'max_depth': 20,\n",
    " 'min_child_weight': 2.0,\n",
    " 'reg_lambda': 0.7764276919090378,\n",
    " 'subsample': 0.3738444042140795,\n",
    "         # Fixed parameters\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 39,\n",
    "        'verbosity': 0,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'device':'cuda',\n",
    "        'tree_method': 'hist'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bst.predict(dtest)\n",
    "submission = pd.DataFrame(predictions,\n",
    "                          columns=label_encoder.classes_,\n",
    "                          index=id_test)\n",
    "submission.to_csv('models/XGBM - sincos buckieting model tuned.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val loss: 2.5003795260570145    keggle: 2.52143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM\n",
    "\n",
    "| Model           | Metoda                             | Wynik CV                | Wynik Kaggle          |\n",
    "|-----------------|--------------------------------------|-------------------------|-----------------------|\n",
    "| LGBM         | Bez hiperparametrów                  | 2.59236                 | 2.68984               |\n",
    "| LGBM         | Pipeline 1                           | 2.31692                 | 2.32228               |\n",
    "| LGBM         | Pipeline 2                           | 2.32257                 | 2.37876               |\n",
    "| LGBM         | Pipeline 3                           | 2.39088                 | 2.40186               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "\n",
    "    params = {\n",
    "\n",
    "        # Search Parameters\n",
    "        'learning_rate': float(params['learning_rate']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'bagging_fraction': float(params['bagging_fraction']),\n",
    "        'feature_fraction': float(params['feature_fraction']),\n",
    "        'reg_lambda': float(params['reg_lambda']),\n",
    "\n",
    "\n",
    "        # Fixed Parameters\n",
    "        'force_col_wise': 'true',\n",
    "        'verbose': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 39\n",
    "\n",
    "    }\n",
    "\n",
    "    # LightBGM classifier\n",
    "    cv_results = lgbm.cv(params, train, metrics='multi_logloss',\n",
    "                         num_boost_round=100, nfold=5, stratified=True, shuffle=True)\n",
    "\n",
    "    loss = min(cv_results['valid multi_logloss-mean'])\n",
    "    epochs = np.argmin(cv_results['valid multi_logloss-mean']) + 1\n",
    "\n",
    "    print('loss: ', loss)\n",
    "\n",
    "    return {\n",
    "        'loss': loss,\n",
    "        'params': params,\n",
    "        'status': STATUS_OK,\n",
    "        'epochs': epochs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1)),\n",
    "    'max_depth': hp.quniform('max_depth', 1, 20, 1),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.0, 1.0),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.0, 1.0),\n",
    "    'num_leaves': hp.quniform('gbdt_num_leaves', 5, 50, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = base_df\n",
    "train = lgbm.Dataset(X_train, label=y, categorical_feature=[0],free_raw_data=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe_algo = tpe.suggest\n",
    "\n",
    "tpe_trials = Trials()\n",
    "\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe_algo,\n",
    "    max_evals=10,\n",
    "    trials=tpe_trials\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]\n",
    "loss:                                                 \n",
    "2.6677862752093686                                    \n",
    "loss:                                                                              \n",
    "2.575902346837997                                                                  \n",
    "loss:                                                                              \n",
    "2.418834835955627                                                                 \n",
    "loss:                                                                             \n",
    "2.316923463173695                                                               \n",
    "loss:                                                                           \n",
    "2.352342391515032                                                               \n",
    "loss:                                                                           \n",
    "2.366662449509916                                                               \n",
    "loss:                                                                           \n",
    "2.3170386802382943                                                                \n",
    "loss:                                                                             \n",
    "2.3636252449281847                                                                \n",
    "loss:                                                                             \n",
    "2.3428560390238427                                                                \n",
    "loss:                                                                             \n",
    "2.4397639503117317                                                                \n",
    "100%|██████████| 10/10 [1:25:16<00:00, 511.60s/trial, best loss: 2.316923463173695]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bagging_fraction': 0.9810700845464868,\n",
    "          'feature_fraction': 0.42462131607761644,\n",
    "          'gbdt_num_leaves': 37,\n",
    "          'learning_rate': 0.2155168538629674,\n",
    "          'max_depth': int(5),\n",
    "          'reg_lambda': 0.976507677160282,\n",
    "          'force_col_wise': 'true',\n",
    "          'verbose': -1,\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'multiclass',\n",
    "          'num_class': 39\n",
    "\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgbm.train(params, train, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bst.predict(X_test)\n",
    "submission = pd.DataFrame(predictions,\n",
    "                          columns=label_encoder.classes_,\n",
    "                          index=id_test)\n",
    "submission.to_csv('LGBM - base model tuned.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val loss 2.3169234631736 kaggle 2.32228"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SinCos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train3 = sincos_transformer.fit_transform(X_train)\n",
    "df_test3 = sincos_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat_label', categorical_transformer_label, ['PdDistrict']),\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(df_train3)\n",
    "X_test = preprocessor.transform(df_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lgbm.Dataset(X_train, label=y, categorical_feature=[0], free_raw_data=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe_algo = tpe.suggest\n",
    "tpe_trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe_algo,\n",
    "    max_evals=10,\n",
    "    trials=tpe_trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bagging_fraction': 0.4828385421929686,\n",
    "          'feature_fraction': 0.5391472756753458,\n",
    "          'gbdt_num_leaves': 47.0,\n",
    "          'learning_rate': 0.21951141536344673,\n",
    "          'max_depth': int(6.0),\n",
    "          'reg_lambda': 0.2938920884793351,\n",
    "          'force_col_wise': 'true',\n",
    "          'verbose': -1,\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'multiclass',\n",
    "          'num_class': 39\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgbm.train(params, train, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bst.predict(X_test)\n",
    "submission = pd.DataFrame(predictions,\n",
    "                          columns=label_encoder.classes_,\n",
    "                          index=id_test)\n",
    "submission.to_csv('models/LGBM - sincos model tuned.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAL LOSS 2.32 KAGGLE 2.37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2 = bucketing_transformer.fit_transform(df_train)\n",
    "df_test2 = bucketing_transformer.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2.sector_x.fillna(8, inplace=True)\n",
    "df_test2.sector_y.fillna(8, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat_label', categorical_transformer_label, ['PdDistrict']),\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(df_train2)\n",
    "X_test = preprocessor.transform(df_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lgbm.Dataset(X_train, label=y, categorical_feature=[0],free_raw_data=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe_algo = tpe.suggest\n",
    "\n",
    "tpe_trials = Trials()\n",
    "\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe_algo,\n",
    "    max_evals=30,\n",
    "    trials=tpe_trials\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss:                                                 \n",
    "2.4726554765201167                                    \n",
    "loss:                                                                              \n",
    "2.4916876076539127                                                                 \n",
    "loss:                                                                              \n",
    "2.8252750786175516                                                                 \n",
    "loss:                                                                              \n",
    "2.412484439664079                                                                  \n",
    "loss:                                                                              \n",
    "2.412417123577532                                                                 \n",
    "loss:                                                                             \n",
    "2.4642874147822167                                                                \n",
    "loss:                                                                             \n",
    "2.4735694714395207                                                                \n",
    "loss:                                                                             \n",
    "2.484860627436979                                                                   \n",
    "loss:                                                                               \n",
    "2.4234691805312636                                                                  \n",
    "loss:                                                                               \n",
    "2.3953974528578654                                                                  \n",
    "loss:                                                                                 \n",
    "2.437728918624332                                                                     \n",
    "loss:                                                                                 \n",
    "2.4054962286828347                                                                    \n",
    "loss:                                                                                 \n",
    "...\n",
    "2.4023219673620266                                                                  \n",
    "loss:                                                                               \n",
    "2.390885226293963                                                                   \n",
    "100%|██████████| 30/30 [4:23:44<00:00, 527.49s/trial, best loss: 2.390885226293963] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bagging_fraction': 0.529092163194387,\n",
    "          'feature_fraction': 0.4410500133711229,\n",
    "          'gbdt_num_leaves': 46.0,\n",
    "          'learning_rate': 0.09823954487471348,\n",
    "          'max_depth': int(14.0),\n",
    "          'reg_lambda': 0.20317611010438422,\n",
    "          'force_col_wise': 'true',\n",
    "          'verbose': -1,\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'multiclass',\n",
    "          'num_class': 39\n",
    "\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgbm.train(params, train, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bst.predict(X_test)\n",
    "submission = pd.DataFrame(predictions,\n",
    "                          columns=label_encoder.classes_,\n",
    "                          index=id_test)\n",
    "submission.to_csv('models/LGBM - sincos bucketing model tuned.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAL LOSS 2.390885226293963 KAGGLE 2.40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ewaluujemy model z najlepszym wynikiem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'colsample_bytree': 0.8399515080498189,\n",
    "    'gamma': 1.8809687874683567,\n",
    "    'learning_rate': 0.15019457619783694,\n",
    "    'max_depth': 12,\n",
    "    'min_child_weight': 9.0,\n",
    "    'reg_lambda': 0.3917588749286913,\n",
    "    'subsample': 0.8665760243726364,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 39,\n",
    "    'verbosity': 0,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'tree_method': 'hist',\n",
    "    'n_estimators': 1000\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>PARK</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878044</th>\n",
       "      <td>2003-01-06 00:15:00</td>\n",
       "      <td>TARAVAL</td>\n",
       "      <td>-122.459033</td>\n",
       "      <td>37.714056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878045</th>\n",
       "      <td>2003-01-06 00:01:00</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>-122.447364</td>\n",
       "      <td>37.731948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878046</th>\n",
       "      <td>2003-01-06 00:01:00</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>-122.403390</td>\n",
       "      <td>37.780266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878047</th>\n",
       "      <td>2003-01-06 00:01:00</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>-122.390531</td>\n",
       "      <td>37.780607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878048</th>\n",
       "      <td>2003-01-06 00:01:00</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>-122.394926</td>\n",
       "      <td>37.738212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>875726 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Dates PdDistrict           X          Y\n",
       "0       2015-05-13 23:53:00   NORTHERN -122.425892  37.774599\n",
       "1       2015-05-13 23:53:00   NORTHERN -122.425892  37.774599\n",
       "2       2015-05-13 23:33:00   NORTHERN -122.424363  37.800414\n",
       "3       2015-05-13 23:30:00   NORTHERN -122.426995  37.800873\n",
       "4       2015-05-13 23:30:00       PARK -122.438738  37.771541\n",
       "...                     ...        ...         ...        ...\n",
       "878044  2003-01-06 00:15:00    TARAVAL -122.459033  37.714056\n",
       "878045  2003-01-06 00:01:00  INGLESIDE -122.447364  37.731948\n",
       "878046  2003-01-06 00:01:00   SOUTHERN -122.403390  37.780266\n",
       "878047  2003-01-06 00:01:00   SOUTHERN -122.390531  37.780607\n",
       "878048  2003-01-06 00:01:00    BAYVIEW -122.394926  37.738212\n",
       "\n",
       "[875726 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sin = sincos_transformer.fit_transform(df_train)\n",
    "df_test_sin = sincos_transformer.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat_label', categorical_transformer_label, ['PdDistrict']),\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(**params))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soszy\\anaconda3\\envs\\psi_project\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1624: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat_label&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;label&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;PdDistrict&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.8399515080498189, device=None,\n",
       "                               early_stopping_round...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.15019457619783694, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=12,\n",
       "                               max_leaves=None, min_child_weight=9.0,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=1000,\n",
       "                               n_jobs=None, num_class=39,\n",
       "                               num_parallel_tree=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat_label&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;label&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;PdDistrict&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.8399515080498189, device=None,\n",
       "                               early_stopping_round...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.15019457619783694, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=12,\n",
       "                               max_leaves=None, min_child_weight=9.0,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=1000,\n",
       "                               n_jobs=None, num_class=39,\n",
       "                               num_parallel_tree=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat_label&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;label&#x27;, OrdinalEncoder())]),\n",
       "                                 [&#x27;PdDistrict&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat_label</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;PdDistrict&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OrdinalEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OrdinalEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;X&#x27;, &#x27;Y&#x27;, &#x27;is_weekend&#x27;, &#x27;hourcos&#x27;, &#x27;monthcos&#x27;, &#x27;quartercos&#x27;, &#x27;dayofyearcos&#x27;, &#x27;daycos&#x27;, &#x27;dayofweekcos&#x27;, &#x27;hoursin&#x27;, &#x27;monthsin&#x27;, &#x27;quartersin&#x27;, &#x27;dayofyearsin&#x27;, &#x27;daysin&#x27;, &#x27;dayofweeksin&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8399515080498189, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;mlogloss&#x27;, feature_types=None,\n",
       "              gamma=1.8809687874683567, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.15019457619783694,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=12, max_leaves=None,\n",
       "              min_child_weight=9.0, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None, num_class=39,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat_label',\n",
       "                                                  Pipeline(steps=[('label',\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  ['PdDistrict'])])),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.8399515080498189, device=None,\n",
       "                               early_stopping_round...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.15019457619783694, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=12,\n",
       "                               max_leaves=None, min_child_weight=9.0,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=1000,\n",
       "                               n_jobs=None, num_class=39,\n",
       "                               num_parallel_tree=None, ...))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_.fit(df_train_sin, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5557006e-03, 1.3274600e-01, 1.1195862e-04, ..., 1.6885036e-01,\n",
       "        2.6564455e-02, 1.7516308e-02],\n",
       "       [3.7755324e-03, 1.2994067e-01, 9.8932673e-05, ..., 9.0842836e-02,\n",
       "        6.9496982e-02, 2.1187212e-02],\n",
       "       [1.0574546e-03, 3.7685674e-02, 9.3225659e-05, ..., 1.4754875e-01,\n",
       "        1.3255123e-02, 3.9884122e-03],\n",
       "       ...,\n",
       "       [2.0255581e-03, 6.4184837e-02, 1.8616297e-03, ..., 1.4615826e-02,\n",
       "        2.4931779e-02, 7.1453420e-03],\n",
       "       [2.2165834e-03, 5.1004346e-02, 1.8149982e-03, ..., 1.1548169e-02,\n",
       "        1.7895738e-02, 1.7141821e-02],\n",
       "       [1.9769953e-03, 5.9456471e-02, 3.0137259e-03, ..., 2.7621713e-02,\n",
       "        1.3696849e-02, 5.8788541e-03]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_.predict_proba(df_test_sin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dalsze kroki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ewaluujemy tylko model z najlepszym wynikiem. Obecnie mamy ograniczenie do 10 ewaluacji ze względu na ograniczenia sprzętowe. Aby przeprowadzić więcej ewaluacji i znaleźć optymalne hiperparametry, musimy zdobyć większą moc obliczeniową poprzez lepszy sprzęt lub skorzystanie z usług chmurowych."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
